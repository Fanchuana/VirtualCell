data:
  name: PerturbationDataModule
  kwargs:
    toml_config_path: /work/home/cryoem666/czx/project/state_training_debug/config/jurkat.toml
    embed_key: null
    output_space: gene
    pert_rep: onehot
    basal_rep: sample
    num_workers: 16
    pin_memory: true
    n_basal_samples: 1
    basal_mapping_strategy: random
    should_yield_control_cells: true
    batch_col: gem_group
    pert_col: gene
    cell_type_key: cell_line
    control_pert: non-targeting
    map_controls: true
    perturbation_features_file: null
    store_raw_basal: false
    int_counts: false
    barcode: true
  output_dir: null
  debug: true
model:
  name: our_state
  checkpoint: null
  device: cuda
  kwargs:
    loss: ba
    sinkhorn_weight: 1
    mean_weight: 1
    cov_weight: 1
    cell_set_len: 64
    blur: 0.05
    hidden_dim: 128
    confidence_head: false
    n_encoder_layers: 1
    n_decoder_layers: 1
    predict_residual: true
    softplus: true
    freeze_pert_backbone: false
    transformer_decoder: false
    finetune_vci_decoder: false
    residual_decoder: false
    batch_encoder: true
    use_batch_token: false
    nb_decoder: false
    mask_attn: false
    use_effect_gating_token: false
    distributional_loss: energy
    init_from: null
    transformer_backbone_key: llama
    transformer_backbone_kwargs:
      bidirectional_attention: false
      max_position_embeddings: 64
      hidden_size: 128
      intermediate_size: 2784
      num_hidden_layers: 8
      num_attention_heads: 12
      num_key_value_heads: 12
      head_dim: 58
      use_cache: false
      attention_dropout: 0.0
      hidden_dropout: 0.0
      layer_norm_eps: 1.0e-06
      pad_token_id: 0
      bos_token_id: 1
      eos_token_id: 2
      tie_word_embeddings: false
      rotary_dim: 0
      use_rotary_embeddings: false
    lora:
      enable: false
      r: 16
      alpha: 32
      dropout: 0.05
      bias: none
      target: auto
      adapt_mlp: false
      task_type: FEATURE_EXTRACTION
      merge_on_eval: false
training:
  wandb_track: true
  weight_decay: 0.0005
  batch_size: 64
  lr: 0.001
  max_steps: 80000
  train_seed: 42
  val_freq: 2000
  ckpt_every_n_steps: 2000
  gradient_clip_val: 10
  gradient_accumulation_steps: 1
  loss_fn: mse
  devices: 1
  strategy: auto
  use_mfu: true
  mfu_kwargs:
    available_flops: 60000000000000.0
    use_backward: true
    logging_interval: 10
    window_size: 2
  cumulative_flops_use_backward: true
wandb:
  entity: your_entity_name
  project: state
  local_wandb_dir: ./wandb_logs
  tags:
  - replogle_run_jurkat
name: jurkat
output_dir: /work/home/cryoem666/czx/project/state_training_debug/experiment/ba_loss_01_09/model_output/all_3_loss
use_wandb: false
overwrite: false
return_adatas: false
pred_adata_path: null
true_adata_path: null
